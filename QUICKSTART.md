# üöÄ Quick Start - GUATEPASS Slice #1

Gu√≠a r√°pida para desplegar y probar el sistema en menos de 10 minutos.

---

## ‚ö° Despliegue R√°pido (3 comandos)

### 1Ô∏è‚É£ Validar y construir

```bash
sam validate -t infrastructure/template.yaml && sam build -t infrastructure/template.yaml
```

### 2Ô∏è‚É£ Desplegar

```bash
sam deploy --guided
```

**Respuestas recomendadas:**
- Stack Name: `guatepass-slice1`
- AWS Region: `us-east-1`
- Parameter Environment: `dev`
- Confirm changes: `y`
- Allow IAM role creation: `Y`
- Authorization not defined: `y`
- Save config: `Y`

### 3Ô∏è‚É£ Cargar datos

```bash
# Obtener nombre del bucket
BUCKET=$(aws cloudformation describe-stacks --stack-name guatepass-slice1 --query 'Stacks[0].Outputs[?OutputKey==`DataBucketName`].OutputValue' --output text)

# Subir CSV
aws s3 cp data/clientes.csv s3://$BUCKET/clientes.csv
```

---

## ‚úÖ Verificaci√≥n

### Ver logs de importaci√≥n

```bash
sam logs -n ImportUsersFunction --stack-name guatepass-slice1 --tail
```

**Buscar:**
```
[SUCCESS] Importaci√≥n completada: {'total': 10, 'success': 10, 'errors': 0}
```

### Consultar usuarios importados

```bash
# Obtener nombre de tabla
TABLE=$(aws cloudformation describe-stacks --stack-name guatepass-slice1 --query 'Stacks[0].Outputs[?OutputKey==`UsersTableName`].OutputValue' --output text)

# Ver primeros 5 usuarios
aws dynamodb scan --table-name $TABLE --max-items 5
```

### Acceder al Dashboard

```bash
aws cloudformation describe-stacks --stack-name guatepass-slice1 --query 'Stacks[0].Outputs[?OutputKey==`DashboardURL`].OutputValue' --output text
```

---

## üõ†Ô∏è Scripts √ötiles (Opcional)

Si prefieres usar scripts automatizados:

```bash
# Dar permisos de ejecuci√≥n (Linux/Mac)
chmod +x scripts/*.sh

# Desplegar todo
./scripts/deploy.sh

# Cargar CSV
./scripts/upload-csv.sh

# Verificar datos
./scripts/check-data.sh

# Limpiar todo
./scripts/cleanup.sh
```

---

## üß™ Testing de Escalabilidad

### Generar CSV grande

```bash
# Generar 1,000 usuarios
python scripts/generate_test_csv.py --users 1000 --output data/clientes_1k.csv

# Subir
aws s3 cp data/clientes_1k.csv s3://$BUCKET/clientes_1k.csv

# Monitorear duraci√≥n
sam logs -n ImportUsersFunction --stack-name guatepass-slice1 --tail
```

---

## üéì Para Presentaci√≥n

### Demo en vivo

1. **Mostrar arquitectura:** `docs/slice1-arquitectura.md`
2. **Mostrar IaC:** `infrastructure/template.yaml`
3. **Subir CSV:** Ejecutar comando de carga
4. **Mostrar logs:** En tiempo real con `sam logs --tail`
5. **Mostrar dashboard:** Abrir URL de CloudWatch
6. **Consultar datos:** Mostrar scan de DynamoDB

### M√©tricas clave a mostrar

- ‚úÖ Lambda: Invocations, Errors (debe ser 0), Duration
- ‚úÖ DynamoDB: Items count, Write capacity consumed
- ‚úÖ Logs: Mensaje de SUCCESS con estad√≠sticas

---

## üßπ Limpiar Recursos

```bash
# Vaciar bucket
aws s3 rm s3://$BUCKET --recursive

# Eliminar stack
sam delete --stack-name guatepass-slice1
```

---

## ‚ùì Troubleshooting Com√∫n

### "Template format error"
```bash
sam validate -t infrastructure/template.yaml
```

### "AccessDenied" al subir CSV
Verificar credenciales:
```bash
aws sts get-caller-identity
```

### Lambda no se dispara
Verificar que el archivo se llama `clientes*.csv`:
```bash
aws s3 ls s3://$BUCKET/
```

---

## üìö Documentaci√≥n Completa

Para m√°s detalles, ver:
- **README.md** - Gu√≠a completa
- **docs/slice1-arquitectura.md** - Decisiones arquitect√≥nicas

---

**Tiempo estimado:** ‚è±Ô∏è 8-10 minutos

**Costo:** üí∞ Free Tier (primeras ejecuciones gratis)

