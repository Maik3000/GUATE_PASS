# ğŸš— GUATEPASS - Sistema de Cobro Automatizado de Peajes

Sistema serverless para el cobro automatizado de peajes en la Ciudad de Guatemala, construido 100% con servicios administrados de AWS.

---

## ğŸ“‹ Tabla de Contenidos

- [Estado del Proyecto](#estado-del-proyecto)
- [Arquitectura](#arquitectura)
- [Prerrequisitos](#prerrequisitos)
- [InstalaciÃ³n y Despliegue](#instalaciÃ³n-y-despliegue)
- [Uso del Sistema](#uso-del-sistema)
- [Monitoreo](#monitoreo)
- [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Estado del Proyecto

### âœ… Slice #1: Carga Inicial de Datos (COMPLETADO)

Componentes implementados:
- âœ… Bucket S3 para almacenamiento de datos iniciales
- âœ… Tabla DynamoDB `GuatepassUsers`
- âœ… Lambda `ImportUsersFunction` con trigger S3
- âœ… Dashboard de CloudWatch
- âœ… Alarmas de monitoreo
- âœ… Infrastructure as Code (SAM)

### ğŸ”œ PrÃ³ximos Slices

- â³ Slice #2: API de Consulta de Usuarios
- â³ Slice #3: Webhook de Peajes y EventBridge
- â³ Slice #4: Procesamiento de Transacciones con Step Functions
- â³ Slice #5: GestiÃ³n de Tags
- â³ Slice #6: Notificaciones

---

## ğŸ—ï¸ Arquitectura

### Slice #1: Carga Inicial de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data/          â”‚
â”‚  clientes.csv   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ (upload manual)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  S3 Bucket                  â”‚
â”‚  guatepass-data-{env}       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ (trigger S3:ObjectCreated)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Lambda                     â”‚
â”‚  ImportUsersFunction        â”‚
â”‚  - Parse CSV                â”‚
â”‚  - Validate data            â”‚
â”‚  - Batch write              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ (batch write)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DynamoDB                   â”‚
â”‚  GuatepassUsers             â”‚
â”‚  PK: placa                  â”‚
â”‚  GSI: tag_id                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Prerrequisitos

### Software Necesario

1. **AWS CLI** (versiÃ³n 2.x)
   ```bash
   aws --version
   # aws-cli/2.x.x o superior
   ```

2. **AWS SAM CLI**
   ```bash
   sam --version
   # SAM CLI, version 1.100.0 o superior
   ```

3. **Python 3.11**
   ```bash
   python --version
   # Python 3.11.x
   ```

4. **Git**
   ```bash
   git --version
   ```

### ConfiguraciÃ³n de AWS

1. **Credenciales configuradas**
   ```bash
   aws configure
   # AWS Access Key ID: [tu-access-key]
   # AWS Secret Access Key: [tu-secret-key]
   # Default region name: us-east-1
   # Default output format: json
   ```

2. **Verificar credenciales**
   ```bash
   aws sts get-caller-identity
   ```

### Permisos IAM Necesarios

El usuario/rol de AWS debe tener permisos para:
- CloudFormation (crear/actualizar stacks)
- S3 (crear buckets, subir objetos)
- Lambda (crear funciones, configurar triggers)
- DynamoDB (crear tablas, escribir items)
- IAM (crear roles y polÃ­ticas)
- CloudWatch (crear dashboards, alarmas, log groups)

---

## ğŸš€ InstalaciÃ³n y Despliegue

### Paso 1: Clonar el Repositorio

```bash
cd /tu/directorio/de/trabajo
# Si ya estÃ¡s en el directorio GUATE_PASS, continÃºa al siguiente paso
```

### Paso 2: Validar el Template de SAM

```bash
sam validate -t infrastructure/template.yaml
```

**Salida esperada:**
```
infrastructure/template.yaml is a valid SAM Template
```

### Paso 3: Build de la AplicaciÃ³n

```bash
sam build -t infrastructure/template.yaml
```

**Salida esperada:**
```
Build Succeeded

Built Artifacts  : .aws-sam/build
Built Template   : .aws-sam/build/template.yaml
```

### Paso 4: Desplegar en AWS

#### OpciÃ³n A: Despliegue Guiado (Primera vez)

```bash
sam deploy --guided
```

**Responde las preguntas:**
```
Stack Name [sam-app]: guatepass-slice1
AWS Region [us-east-1]: us-east-1
Parameter Environment [dev]: dev
Confirm changes before deploy [y/N]: y
Allow SAM CLI IAM role creation [Y/n]: Y
Disable rollback [y/N]: N
ImportUsersFunction may not have authorization defined, Is this okay? [y/N]: y
Save arguments to configuration file [Y/n]: Y
SAM configuration file [samconfig.toml]: samconfig.toml
SAM configuration environment [default]: default
```

#### OpciÃ³n B: Despliegue Directo (DespuÃ©s de la primera vez)

```bash
sam deploy
```

### Paso 5: Verificar el Despliegue

```bash
aws cloudformation describe-stacks --stack-name guatepass-slice1 --query 'Stacks[0].StackStatus'
```

**Salida esperada:**
```
"CREATE_COMPLETE"
```

### Paso 6: Obtener Outputs del Stack

```bash
aws cloudformation describe-stacks --stack-name guatepass-slice1 --query 'Stacks[0].Outputs'
```

**Guardar estos valores:**
- `DataBucketName`: Nombre del bucket S3
- `UsersTableName`: Nombre de la tabla DynamoDB
- `ImportUsersFunctionArn`: ARN de la funciÃ³n Lambda
- `DashboardURL`: URL del dashboard de CloudWatch

---

## ğŸ’» Uso del Sistema

### 1. Cargar Datos Iniciales

El archivo CSV de clientes estÃ¡ en `data/clientes.csv`. Para cargarlo al sistema:

#### Obtener el nombre del bucket

```bash
BUCKET_NAME=$(aws cloudformation describe-stacks --stack-name guatepass-slice1 --query 'Stacks[0].Outputs[?OutputKey==`DataBucketName`].OutputValue' --output text)
echo $BUCKET_NAME
```

#### Subir el archivo CSV

```bash
aws s3 cp data/clientes.csv s3://$BUCKET_NAME/clientes.csv
```

**Salida esperada:**
```
upload: data/clientes.csv to s3://guatepass-data-dev-123456789012/clientes.csv
```

### 2. Verificar la EjecuciÃ³n de la Lambda

#### Ver logs en tiempo real

```bash
sam logs -n ImportUsersFunction --stack-name guatepass-slice1 --tail
```

**Buscar en los logs:**
```
[INFO] Iniciando importaciÃ³n de usuarios
[INFO] Total de usuarios en CSV: 10
[SUCCESS] ImportaciÃ³n completada: {'total': 10, 'success': 10, 'errors': 0}
```

#### Ver logs recientes (Ãºltimos 10 minutos)

```bash
aws logs tail /aws/lambda/guatepass-import-users-dev --since 10m
```

### 3. Verificar los Datos en DynamoDB

#### OpciÃ³n A: AWS CLI

```bash
# Obtener nombre de la tabla
TABLE_NAME=$(aws cloudformation describe-stacks --stack-name guatepass-slice1 --query 'Stacks[0].Outputs[?OutputKey==`UsersTableName`].OutputValue' --output text)

# Escanear la tabla (primeros 10 items)
aws dynamodb scan --table-name $TABLE_NAME --max-items 10
```

#### OpciÃ³n B: Consultar un usuario especÃ­fico

```bash
aws dynamodb get-item \
  --table-name $TABLE_NAME \
  --key '{"placa": {"S": "P-123ABC"}}'
```

**Salida esperada:**
```json
{
  "Item": {
    "placa": {"S": "P-123ABC"},
    "nombre": {"S": "Juan PÃ©rez"},
    "email": {"S": "juan@email.com"},
    "telefono": {"S": "50212345678"},
    "tipo_usuario": {"S": "registrado"},
    "tiene_tag": {"BOOL": false},
    "saldo_disponible": {"N": "100.00"},
    "estado": {"S": "activo"}
  }
}
```

#### OpciÃ³n C: Contar usuarios importados

```bash
aws dynamodb scan \
  --table-name $TABLE_NAME \
  --select "COUNT"
```

### 4. Probar con Diferentes Archivos CSV

Puedes crear tu propio CSV y subirlo:

```bash
# Crear un nuevo archivo
cat > data/clientes_test.csv << EOF
placa,nombre,email,telefono,tipo_usuario,tiene_tag,tag_id,saldo_disponible
P-999ZZZ,Usuario Test,test@email.com,50299999999,registrado,false,,500.00
EOF

# Subirlo
aws s3 cp data/clientes_test.csv s3://$BUCKET_NAME/clientes_test.csv
```

---

## ğŸ“Š Monitoreo

### Dashboard de CloudWatch

Accede al dashboard desde la consola de AWS o usa la URL del Output:

```bash
# Obtener URL del dashboard
aws cloudformation describe-stacks \
  --stack-name guatepass-slice1 \
  --query 'Stacks[0].Outputs[?OutputKey==`DashboardURL`].OutputValue' \
  --output text
```

El dashboard muestra:
- **Lambda Metrics**: Invocaciones, errores, duraciÃ³n
- **DynamoDB Capacity**: Unidades de lectura/escritura consumidas
- **Recent Errors**: Log query de errores recientes

### MÃ©tricas Principales

#### Invocaciones de Lambda

```bash
aws cloudwatch get-metric-statistics \
  --namespace AWS/Lambda \
  --metric-name Invocations \
  --dimensions Name=FunctionName,Value=guatepass-import-users-dev \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 3600 \
  --statistics Sum
```

#### Errores de Lambda

```bash
aws cloudwatch get-metric-statistics \
  --namespace AWS/Lambda \
  --metric-name Errors \
  --dimensions Name=FunctionName,Value=guatepass-import-users-dev \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 3600 \
  --statistics Sum
```

### Alarmas

Una alarma estÃ¡ configurada para notificar si la Lambda tiene errores:

```bash
# Ver estado de la alarma
aws cloudwatch describe-alarms \
  --alarm-names guatepass-import-users-errors-dev
```

---

## ğŸ”§ Troubleshooting

### Problema: "Template format error: [/Resources/ImportUsersFunction] ..."

**Causa:** Error de sintaxis en el template YAML.

**SoluciÃ³n:**
```bash
sam validate -t infrastructure/template.yaml
# Corrige los errores indicados
```

### Problema: "AccessDenied when calling S3 operation"

**Causa:** La Lambda no tiene permisos para leer el bucket.

**SoluciÃ³n:** Verifica que el template incluye la policy `S3ReadPolicy`.

### Problema: "CSV no se procesa / Lambda no se dispara"

**DiagnÃ³stico:**
```bash
# 1. Verificar que el archivo existe
aws s3 ls s3://$BUCKET_NAME/

# 2. Verificar trigger de Lambda
aws lambda get-function --function-name guatepass-import-users-dev

# 3. Ver logs de errores
aws logs tail /aws/lambda/guatepass-import-users-dev --since 30m --filter-pattern ERROR
```

**SoluciÃ³n:** AsegÃºrate de que el archivo se llama `clientes*.csv` (el trigger filtra por prefijo `clientes` y sufijo `.csv`).

### Problema: "DynamoDB Throttling"

**SÃ­ntoma:** Errores de tipo `ProvisionedThroughputExceededException`.

**Causa:** Tabla en modo PAY_PER_REQUEST no deberÃ­a tener throttling a menos que excedas 40,000 WCU/s.

**SoluciÃ³n temporal:**
```bash
# Ver mÃ©tricas de throttling
aws cloudwatch get-metric-statistics \
  --namespace AWS/DynamoDB \
  --metric-name UserErrors \
  --dimensions Name=TableName,Value=$TABLE_NAME \
  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 300 \
  --statistics Sum
```

### Problema: "La importaciÃ³n se completa pero hay errores"

**DiagnÃ³stico:**
```bash
# Ver logs completos de la Ãºltima ejecuciÃ³n
sam logs -n ImportUsersFunction --stack-name guatepass-slice1

# Buscar lÃ­neas con [ERROR] o [WARNING]
```

**Causas comunes:**
- Formato de CSV incorrecto (comas faltantes, comillas mal cerradas)
- Valores invÃ¡lidos en campos numÃ©ricos
- Placas duplicadas

---

## ğŸ§¹ Limpiar Recursos

Para eliminar todos los recursos creados:

### Paso 1: Vaciar el Bucket S3

```bash
aws s3 rm s3://$BUCKET_NAME --recursive
```

### Paso 2: Eliminar el Stack

```bash
sam delete --stack-name guatepass-slice1
```

O con confirmaciÃ³n:

```bash
aws cloudformation delete-stack --stack-name guatepass-slice1
```

### Paso 3: Verificar EliminaciÃ³n

```bash
aws cloudformation describe-stacks --stack-name guatepass-slice1
# DeberÃ­a mostrar: "Stack with id guatepass-slice1 does not exist"
```

---

## ğŸ“š Estructura del Proyecto

```
GUATE_PASS/
â”œâ”€â”€ README.md                           # Este archivo
â”œâ”€â”€ infrastructure/
â”‚   â””â”€â”€ template.yaml                   # SAM template (IaC)
â”œâ”€â”€ src/
â”‚   â””â”€â”€ import_users/
â”‚       â”œâ”€â”€ app.py                      # CÃ³digo de la Lambda
â”‚       â””â”€â”€ requirements.txt            # Dependencias Python
â”œâ”€â”€ data/
â”‚   â””â”€â”€ clientes.csv                    # Datos iniciales de clientes
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ slice1-arquitectura.md          # DocumentaciÃ³n de arquitectura
â””â”€â”€ tests/
    â””â”€â”€ (prÃ³ximamente)
```

---

## ğŸ‘¥ Equipo

- **Integrante 1:** [Nombre]
- **Integrante 2:** [Nombre]
- **Integrante 3:** [Nombre]

---

## ğŸ“… Entrega

- **Fecha lÃ­mite:** 17 de noviembre de 2025, 11:59 PM
- **PresentaciÃ³n:** 17 de noviembre de 2025

---

## ğŸ“– Referencias

- [AWS SAM Documentation](https://docs.aws.amazon.com/serverless-application-model/)
- [AWS Lambda Best Practices](https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html)
- [DynamoDB Best Practices](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/best-practices.html)
- [Serverless Patterns Collection](https://serverlessland.com/patterns)

---

## ğŸ“ Notas Importantes

1. **Ambiente de desarrollo:** Este slice estÃ¡ configurado para ambiente `dev`. Para producciÃ³n, despliega con `--parameter-overrides Environment=prod`.

2. **Costos:** Los servicios utilizados estÃ¡n en Free Tier o tienen costos muy bajos:
   - Lambda: Primeros 1M de invocaciones gratis
   - DynamoDB: 25 GB gratis en PAY_PER_REQUEST
   - S3: Primeros 5 GB gratis
   - CloudWatch: 10 mÃ©tricas custom gratis

3. **RetenciÃ³n de logs:** Los logs se retienen por 7 dÃ­as para reducir costos.

4. **Versionamiento S3:** El bucket tiene versionamiento habilitado para seguridad.

---

Â¡Slice #1 completado! ğŸ‰

ContinÃºa con el Slice #2 para agregar la API de consulta de usuarios.

